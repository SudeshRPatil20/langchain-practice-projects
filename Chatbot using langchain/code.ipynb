{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47126305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.54)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.23)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain_community) (3.11.17)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain_community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.32)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain_community) (2.2.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.11.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.0)\n",
      "Requirement already satisfied: anyio in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.33.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60272443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gorq_api_key=os.getenv(\"GROQ_TESTING_API\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40340716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=gorq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe443da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Sudesh Patil.\\n\\nI remember that you told me earlier! üòä  \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 58, 'total_tokens': 90, 'completion_time': 0.058181818, 'prompt_time': 0.003449243, 'queue_time': 0.235166871, 'total_time': 0.061631061}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f8b6dd09-df0e-4f0e-8a5e-ea59164434d9-0', usage_metadata={'input_tokens': 58, 'output_tokens': 32, 'total_tokens': 90})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"hi my name is Sudesh Patil\"),\n",
    "        AIMessage(content=\"Hello Sudesh Patil, it's nice to meet you! üëã\\n\\nIs there anything I can help you with today?\\n\"),\n",
    "        HumanMessage(content=\"what's my name?\")\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e57e7",
   "metadata": {},
   "source": [
    "### Message History\n",
    "it is concept in langchian which stores the past coversation and use it in further future conversation happend related to that past conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54951ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_messesge_history=RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7a9fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fcfd15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "responce=with_messesge_history.invoke(\n",
    "    [HumanMessage(content=\"hey, my name is Sudesh\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4c8f8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Sudesh, it's nice to meet you! üëã\\n\\nWhat can I do for you today? üòÑ  \\n\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a85ccb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Sudesh!  üòä \\n\\nI remember that from when you first introduced yourself.  \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 58, 'total_tokens': 93, 'completion_time': 0.063636364, 'prompt_time': 0.003602824, 'queue_time': 0.237785837, 'total_time': 0.067239188}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bf591de5-fcd1-4f7c-b8a6-13edaa183bb2-0', usage_metadata={'input_tokens': 58, 'output_tokens': 35, 'total_tokens': 93})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_messesge_history.invoke(\n",
    "    [HumanMessage(content=\"hey what,s my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4cc129e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Sudesh, it's nice to meet you! üëã\\n\\nHow can I help you today? üòä\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "responce=with_messesge_history.invoke(\n",
    "    [HumanMessage(content=\"hey, my name is Sudesh\")],\n",
    "    config=config1\n",
    ")\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37d5ed",
   "metadata": {},
   "source": [
    "### Prompt template\n",
    "it is kind of thing that converts raw message to message that llm can easyly undersatandable and use and give response as per input message let us see how it works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e70eb58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder #this ti mostly used in assigning propts such  that it will best for messages\n",
    "\n",
    "prompts=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are helpful  assisitent.Answer all question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"message\")\n",
    "    ]\n",
    ") \n",
    "\n",
    "chain=prompts|model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b400890d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Sudesh! It's nice to meet you. \\n\\nI'm ready to answer any questions you have to the best of my ability. Ask away! üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 31, 'total_tokens': 71, 'completion_time': 0.072727273, 'prompt_time': 0.002366336, 'queue_time': 0.240085584, 'total_time': 0.075093609}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-032e9b5f-b1da-48fa-91a6-1a669e607c24-0', usage_metadata={'input_tokens': 31, 'output_tokens': 40, 'total_tokens': 71})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"message\":[HumanMessage(content=\"Hi my name is sudesh\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0cf43410",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_messesge_history=RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79d78eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Sudesh, it's nice to meet you! \\n\\nI'm happy to be your helpful assistant.  What can I do for you today? üòä  Just ask away! \\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "responce=with_messesge_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is sudesh\")],\n",
    "    config=config\n",
    ")\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9db2befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as it is very simple let us add more complexityes to it\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder #this ti mostly used in assigning propts such  that it will best for messages\n",
    "\n",
    "prompts=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are helpful  assisitent.Answer all question to the best on {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"message\")\n",
    "    ]\n",
    ") \n",
    "\n",
    "chain=prompts|model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84ffb93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§®‡§æ‡§π‡•Ä, ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§¶‡§§‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§Ø‡•á‡§•‡•á ‡§Ü‡§π‡•á, ‡§∏‡•Å‡§¶‡•á‡§∂! ‡§ï‡•ã‡§£‡§§‡•ç‡§Ø‡§æ‡§π‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§Æ‡§≤‡§æ ‡§µ‡§ø‡§ö‡§æ‡§∞‡•Ç ‡§®‡§ï‡•ã. ‡§Æ‡§≤‡§æ ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§Ü‡§®‡§Ç‡§¶ ‡§π‡•ã‡§à‡§≤.  üòä\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 30, 'total_tokens': 85, 'completion_time': 0.1, 'prompt_time': 0.002164487, 'queue_time': 0.232304383, 'total_time': 0.102164487}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-692678c8-0c7f-487b-8eaf-e1e1aa3d22fe-0', usage_metadata={'input_tokens': 30, 'output_tokens': 55, 'total_tokens': 85})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"message\":[HumanMessage(content=\"Hi my name is sudesh\")],\"language\":\"Marathi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01660624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we sould warp the contennt in morw complicated way\n",
    "with_messesge_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"message\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52980415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Sudesh, it's nice to meet you! \\n\\nI'm happy to be your helpful assistant.  What can I do for you today? üòä  Just ask away! \\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_messesge_history.invoke(\n",
    "    {'message':[HumanMessage(content=\"Hi, I am Sudesh\")], \"language\":\"Marathi\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "211a955b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good ai assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, trim_messages\n",
    "\n",
    "# trimmer is the concept used for save the history of past conversatio  such that chatbot will use the history for future conversation \n",
    "trimmer=trim_messages(\n",
    "     max_tokens=45,\n",
    "     strategy=\"last\",\n",
    "     token_counter=model,\n",
    "     include_system=True,\n",
    "     allow_partial=False,\n",
    "     start_on=\"human\"\n",
    " )\n",
    "\n",
    "message= [\n",
    "    SystemMessage(content=\"you're a good ai assistant\"),\n",
    "    HumanMessage(content=\"hi! i am cheti cool\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like venilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6740ed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\sudesh\\gerative ai\\chatbot using langchain\\venv\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d901d873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Sudesh, it's nice to meet you! \\n\\nI'm happy to be your helpful assistant.  What can I do for you today? üòä  Just ask away! \\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(message=itemgetter(\"message\")|trimmer)\n",
    "    | prompts\n",
    "    | model\n",
    ")\n",
    "\n",
    "respons=chain.invoke(\n",
    "    {\n",
    "        \"message\": message + [HumanMessage(content=\"What ice cream i like ?\")],\n",
    "        \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "242320bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "respons=chain.invoke(\n",
    "    {\n",
    "        \"message\": message + [HumanMessage(content=\"What problem i asked?\")],\n",
    "        \"language\":\"English\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d16acaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Sudesh, it's nice to meet you! \\n\\nI'm happy to be your helpful assistant.  What can I do for you today? üòä  Just ask away! \\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1669abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we wrap the message\n",
    "with_wrap_message=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"message\",\n",
    "    \n",
    "    \n",
    ")\n",
    "\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b00abf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Sudesh, it's nice to meet you! \\n\\nI'm happy to be your helpful assistant.  What can I do for you today? üòä  Just ask away! \\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respons=with_messesge_history.invoke(\n",
    "    {\n",
    "        \"message\": [HumanMessage(content=\"What ice cream i like ?\")],\n",
    "        \"language\":\"English\"\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d65f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e79e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
